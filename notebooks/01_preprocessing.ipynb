{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147540c6",
   "metadata": {},
   "source": [
    "# Data Consolidation Pipeline\n",
    "## Food Price Clustering Project - Phase 1\n",
    "\n",
    "This notebook consolidates raw food price data from multiple Indonesian cities into a clean, structured format for clustering analysis.\n",
    "\n",
    "### Objectives:\n",
    "1. **Load** raw Excel files from multiple provinces/cities/years\n",
    "2. **Clean** and standardize data formats (dates, prices, missing values)\n",
    "3. **Transform** data into long format suitable for analysis\n",
    "4. **Validate** data quality and completeness\n",
    "5. **Export** consolidated dataset for feature engineering\n",
    "\n",
    "### Data Structure:\n",
    "- **Input**: Excel files organized by `Province/City/Year.xlsx`\n",
    "- **Output**: Consolidated DataFrame with columns: `[Commodity, City, Date, Price]`\n",
    "- **Scope**: 10 food commodities across Indonesian cities (2020-2024)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b5a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Data Consolidation Pipeline - Environment Setup\n",
      "============================================================\n",
      "üìÖ Notebook run at: 2025-10-04 20:06:15\n",
      "üêç Python version: 3.12.7\n",
      "üêº Pandas version: 2.3.3\n",
      "üî¢ NumPy version: 2.3.3\n",
      "\n",
      "üìÇ Path Verification:\n",
      "   Current working directory: c:\\Users\\UNTAR\\Semester 7\\SKRIPSI\\program\\food-price-clustering\\food-price-clustering\n",
      "   Raw data path: data\\raw (‚úÖ EXISTS)\n",
      "   Processed data path: data\\processed (‚úÖ EXISTS)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup and Environment Configuration\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "# Note: Logging is configured in the Configuration cell based on user settings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def setup_environment() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Setup notebook environment and verify paths.\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing environment information and path verification results.\n",
    "    \"\"\"\n",
    "    # Fix working directory - ensure we're running from project root\n",
    "    notebook_dir = Path.cwd()\n",
    "    project_root = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
    "    \n",
    "    # Change to project root so all relative paths work correctly\n",
    "    os.chdir(project_root)\n",
    "    \n",
    "    # Verify critical paths\n",
    "    paths_info = {\n",
    "        'notebook_dir': notebook_dir,\n",
    "        'project_root': project_root,\n",
    "        'current_dir': Path.cwd(),\n",
    "        'raw_data_path': Path('data/raw'),\n",
    "        'raw_data_exists': Path('data/raw').exists(),\n",
    "        'processed_data_path': Path('data/processed'),\n",
    "        'processed_data_exists': Path('data/processed').exists()\n",
    "    }\n",
    "    \n",
    "    # Create processed data directory if it doesn't exist\n",
    "    if not paths_info['processed_data_exists']:\n",
    "        paths_info['processed_data_path'].mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Environment info\n",
    "    env_info = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'python_version': sys.version.split()[0],\n",
    "        'pandas_version': pd.__version__,\n",
    "        'numpy_version': np.__version__\n",
    "    }\n",
    "    \n",
    "    return {**paths_info, **env_info}\n",
    "\n",
    "# Setup environment\n",
    "env_info = setup_environment()\n",
    "\n",
    "# Display environment information\n",
    "print(\"üöÄ Data Consolidation Pipeline - Environment Setup\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìÖ Notebook run at: {env_info['timestamp']}\")\n",
    "print(f\"üêç Python version: {env_info['python_version']}\")\n",
    "print(f\"üêº Pandas version: {env_info['pandas_version']}\")\n",
    "print(f\"üî¢ NumPy version: {env_info['numpy_version']}\")\n",
    "print()\n",
    "print(\"üìÇ Path Verification:\")\n",
    "print(f\"   Current working directory: {env_info['current_dir']}\")\n",
    "print(f\"   Raw data path: {env_info['raw_data_path']} ({'‚úÖ EXISTS' if env_info['raw_data_exists'] else '‚ùå MISSING'})\")\n",
    "print(f\"   Processed data path: {env_info['processed_data_path']} ({'‚úÖ EXISTS' if env_info['processed_data_exists'] else '‚ùå MISSING'})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f352fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 20:06:18,104 - INFO - üì∫ Console logging only (file logging disabled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration Loaded Successfully\n",
      "==================================================\n",
      "üìù File Logging: ‚ùå DISABLED\n",
      "üìä Log Level: INFO\n",
      "üìç Provinces (21): Aceh, Banten, Bengkulu...\n",
      "üìÖ Years (5): 2020, 2021, 2022, 2023, 2024\n",
      "ü•¨ Commodities (10): Beras, Telur Ayam, Daging Ayam...\n",
      "üóëÔ∏è Columns to drop: No\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration Management with Validation\n",
    "\"\"\"\n",
    "\n",
    "class ConsolidationConfig(BaseModel):\n",
    "    \"\"\"\n",
    "    Configuration class for data consolidation pipeline.\n",
    "    \n",
    "    Uses Pydantic for validation and type checking.\n",
    "    \"\"\"\n",
    "    # Logging configuration\n",
    "    enable_file_logging: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether to save logs to file (True) or console only (False)\"\n",
    "    )\n",
    "    \n",
    "    log_level: str = Field(\n",
    "        default=\"INFO\",\n",
    "        description=\"Logging level: DEBUG, INFO, WARNING, ERROR\"\n",
    "    )\n",
    "    \n",
    "    # Data selection parameters (empty list = process all available)\n",
    "    provinces: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"List of provinces to process. Empty list = process all provinces\"\n",
    "    )\n",
    "    \n",
    "    years: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"List of years to process. Empty list = process all years (2020-2024)\"\n",
    "    )\n",
    "    \n",
    "    commodities: List[str] = Field(\n",
    "        default=[\n",
    "            \"Beras\",\n",
    "            \"Telur Ayam\", \n",
    "            \"Daging Ayam\",\n",
    "            \"Daging Sapi\",\n",
    "            \"Bawang Merah\",\n",
    "            \"Bawang Putih\",\n",
    "            \"Cabai Merah\",\n",
    "            \"Cabai Rawit\",\n",
    "            \"Minyak Goreng\",\n",
    "            \"Gula Pasir\"\n",
    "        ],\n",
    "        description=\"List of commodities to include in analysis\"\n",
    "    )\n",
    "    \n",
    "    # Data processing parameters\n",
    "    columns_to_drop: List[str] = Field(\n",
    "        default=[\"No\"],\n",
    "        description=\"Column names to drop from raw data\"\n",
    "    )\n",
    "    \n",
    "    missing_value_indicators: List[str] = Field(\n",
    "        default=[\"-\", \"\", \"nan\", \"NaN\", \"null\", \"NULL\"],\n",
    "        description=\"Values to treat as missing/null\"\n",
    "    )\n",
    "    \n",
    "    # File processing parameters\n",
    "    date_format: str = Field(\n",
    "        default=\"%d/ %m/ %Y\",\n",
    "        description=\"Expected date format in Excel files\"\n",
    "    )\n",
    "    \n",
    "    commodity_column_name: str = Field(\n",
    "        default=\"Komoditas (Rp)\",\n",
    "        description=\"Original name of commodity column in Excel files\"\n",
    "    )\n",
    "    \n",
    "    @field_validator('log_level')\n",
    "    @classmethod\n",
    "    def validate_log_level(cls, v):\n",
    "        valid_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"]\n",
    "        if v.upper() not in valid_levels:\n",
    "            raise ValueError(f\"Log level must be one of: {valid_levels}\")\n",
    "        return v.upper()\n",
    "    \n",
    "    @field_validator('years')\n",
    "    @classmethod\n",
    "    def validate_years(cls, v):\n",
    "        # If empty, it will be populated with all available years later\n",
    "        if not v:\n",
    "            return v\n",
    "            \n",
    "        # Validate year format if provided\n",
    "        for year in v:\n",
    "            try:\n",
    "                year_int = int(year)\n",
    "                if not (2020 <= year_int <= 2024):\n",
    "                    raise ValueError(f\"Year {year} outside expected range 2020-2024\")\n",
    "            except ValueError as e:\n",
    "                if \"invalid literal\" in str(e):\n",
    "                    raise ValueError(f\"Invalid year format: {year}\")\n",
    "                raise\n",
    "        return v\n",
    "    \n",
    "    @field_validator('commodities')\n",
    "    @classmethod\n",
    "    def validate_commodities(cls, v):\n",
    "        if not v:\n",
    "            raise ValueError(\"At least one commodity must be specified\")\n",
    "        if len(v) != len(set(v)):\n",
    "            raise ValueError(\"Duplicate commodities found\")\n",
    "        return v\n",
    "\n",
    "def setup_logging(enable_file_logging: bool = False, log_level: str = \"INFO\") -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Setup logging with optional file output.\n",
    "    \n",
    "    Args:\n",
    "        enable_file_logging: Whether to save logs to file\n",
    "        log_level: Logging level (DEBUG, INFO, WARNING, ERROR)\n",
    "        \n",
    "    Returns:\n",
    "        Configured logger instance\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    logger = logging.getLogger(\"food_price_clustering\")\n",
    "    logger.setLevel(getattr(logging, log_level.upper()))\n",
    "    \n",
    "    # Clear any existing handlers\n",
    "    logger.handlers.clear()\n",
    "    \n",
    "    # Create formatters\n",
    "    detailed_formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'\n",
    "    )\n",
    "    simple_formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    \n",
    "    # Console handler (always enabled)\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(getattr(logging, log_level.upper()))\n",
    "    console_handler.setFormatter(simple_formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    # File handler (optional)\n",
    "    if enable_file_logging:\n",
    "        # Create logs directory\n",
    "        logs_dir = Path(\"logs\")\n",
    "        logs_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Generate timestamped log filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_filename = logs_dir / f\"data_consolidation_{timestamp}.log\"\n",
    "        \n",
    "        file_handler = logging.FileHandler(log_filename, encoding='utf-8')\n",
    "        file_handler.setLevel(logging.DEBUG)  # Log everything to file\n",
    "        file_handler.setFormatter(detailed_formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "        \n",
    "        logger.info(f\"üìù File logging enabled - Log file: {log_filename}\")\n",
    "    else:\n",
    "        logger.info(\"üì∫ Console logging only (file logging disabled)\")\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def discover_available_data(raw_data_path: Path) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Discover all available provinces and years in the raw data directory.\n",
    "    \n",
    "    Args:\n",
    "        raw_data_path: Path to raw data directory\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with 'provinces' and 'years' lists\n",
    "    \"\"\"\n",
    "    available_provinces = []\n",
    "    available_years = set()\n",
    "    \n",
    "    if raw_data_path.exists():\n",
    "        for province_path in raw_data_path.iterdir():\n",
    "            if province_path.is_dir():\n",
    "                available_provinces.append(province_path.name)\n",
    "                \n",
    "                # Check for years in this province\n",
    "                for city_path in province_path.iterdir():\n",
    "                    if city_path.is_dir():\n",
    "                        for file_path in city_path.glob(\"*.xlsx\"):\n",
    "                            year = file_path.stem\n",
    "                            available_years.add(year)\n",
    "    \n",
    "    return {\n",
    "        'provinces': sorted(available_provinces),\n",
    "        'years': sorted(list(available_years))\n",
    "    }\n",
    "\n",
    "# Discover available data\n",
    "raw_data_path = Path(\"data/raw\")\n",
    "available_data = discover_available_data(raw_data_path)\n",
    "\n",
    "# Initialize configuration\n",
    "config = ConsolidationConfig()\n",
    "\n",
    "# Auto-populate empty lists with all available data\n",
    "if not config.provinces:\n",
    "    config.provinces = available_data['provinces']\n",
    "    \n",
    "if not config.years:\n",
    "    config.years = available_data['years']\n",
    "\n",
    "# Setup logging based on configuration\n",
    "logger = setup_logging(config.enable_file_logging, config.log_level)\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration Loaded Successfully\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìù File Logging: {'‚úÖ ENABLED' if config.enable_file_logging else '‚ùå DISABLED'}\")\n",
    "print(f\"üìä Log Level: {config.log_level}\")\n",
    "print(f\"üìç Provinces ({len(config.provinces)}): {', '.join(config.provinces[:3])}{'...' if len(config.provinces) > 3 else ''}\")\n",
    "print(f\"üìÖ Years ({len(config.years)}): {', '.join(config.years)}\")\n",
    "print(f\"ü•¨ Commodities ({len(config.commodities)}): {', '.join(config.commodities[:3])}{'...' if len(config.commodities) > 3 else ''}\")\n",
    "print(f\"üóëÔ∏è Columns to drop: {', '.join(config.columns_to_drop)}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba61648",
   "metadata": {},
   "source": [
    "## Data Processing Functions\n",
    "\n",
    "Now we'll define modular, well-documented functions for each step of the data processing pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cd7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 1: File Discovery\n",
    "\"\"\"\n",
    "\n",
    "def discover_data_files(raw_data_path: Path, config: ConsolidationConfig) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Discover all Excel files matching the configuration criteria.\n",
    "    \n",
    "    Args:\n",
    "        raw_data_path: Path to raw data directory\n",
    "        config: Configuration object with provinces and years to process\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing file metadata\n",
    "    \"\"\"\n",
    "    discovered_files = []\n",
    "    \n",
    "    if not raw_data_path.exists():\n",
    "        raise FileNotFoundError(f\"Raw data path does not exist: {raw_data_path}\")\n",
    "    \n",
    "    for province_path in raw_data_path.iterdir():\n",
    "        if not province_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        if province_path.name not in config.provinces:\n",
    "            continue\n",
    "            \n",
    "        logger.info(f\"Processing province: {province_path.name}\")\n",
    "        \n",
    "        for city_path in province_path.iterdir():\n",
    "            if not city_path.is_dir():\n",
    "                continue\n",
    "                \n",
    "            city_files = []\n",
    "            for file_path in city_path.glob(\"*.xlsx\"):\n",
    "                year = file_path.stem  # filename without extension\n",
    "                if year in config.years:\n",
    "                    file_info = {\n",
    "                        'city': city_path.name,\n",
    "                        'year': year,\n",
    "                        'file_path': file_path,\n",
    "                        'file_size': file_path.stat().st_size\n",
    "                    }\n",
    "                    city_files.append(file_info)\n",
    "                    discovered_files.append(file_info)\n",
    "            \n",
    "            if city_files:\n",
    "                logger.info(f\"  Found {len(city_files)} files for city: {city_path.name}\")\n",
    "    \n",
    "    logger.info(f\"Total files discovered: {len(discovered_files)}\")\n",
    "    return discovered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d272df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 2: Excel File Loading and Initial Cleaning\n",
    "\"\"\"\n",
    "\n",
    "def load_and_clean_excel_file(file_info: Dict[str, Any], config: ConsolidationConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and perform initial cleaning of a single Excel file.\n",
    "    \n",
    "    Args:\n",
    "        file_info: Dictionary containing file metadata\n",
    "        config: Configuration object\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame in long format\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If file cannot be processed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load Excel file\n",
    "        df = pd.read_excel(file_info['file_path'])\n",
    "        logger.debug(f\"Loaded {file_info['file_path']}: {df.shape}\")\n",
    "        \n",
    "        # Validate required columns exist\n",
    "        if config.commodity_column_name not in df.columns:\n",
    "            raise ValueError(f\"Required column '{config.commodity_column_name}' not found in {file_info['file_path']}\")\n",
    "        \n",
    "        # Drop specified columns\n",
    "        columns_to_drop = [col for col in config.columns_to_drop if col in df.columns]\n",
    "        if columns_to_drop:\n",
    "            df = df.drop(columns=columns_to_drop)\n",
    "        \n",
    "        # Rename commodity column\n",
    "        df = df.rename(columns={config.commodity_column_name: \"Commodity\"})\n",
    "        \n",
    "        # Add metadata columns\n",
    "        df[\"City\"] = file_info['city']\n",
    "        df[\"Year\"] = file_info['year']\n",
    "        \n",
    "        # Transform to long format\n",
    "        id_vars = [\"Commodity\", \"City\", \"Year\"]\n",
    "        long_df = df.melt(\n",
    "            id_vars=id_vars,\n",
    "            var_name=\"Date\",\n",
    "            value_name=\"Price\"\n",
    "        )\n",
    "        \n",
    "        return long_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing file {file_info['file_path']}: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to process {file_info['file_path']}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12c45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 3: Missing Values Handling\n",
    "\"\"\"\n",
    "\n",
    "def clean_missing_values(df: pd.DataFrame, config: ConsolidationConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values using forward/backward fill within city-commodity groups.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with potential missing values\n",
    "        config: Configuration object with missing value indicators\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with missing values handled\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Replace missing value indicators with NaN\n",
    "    for indicator in config.missing_value_indicators:\n",
    "        df_clean[\"Price\"] = df_clean[\"Price\"].replace(indicator, np.nan)\n",
    "    \n",
    "    # Sort for proper forward/backward fill\n",
    "    df_clean = df_clean.sort_values([\"City\", \"Commodity\", \"Date\"])\n",
    "    \n",
    "    # Forward fill then backward fill within groups\n",
    "    df_clean[\"Price\"] = (\n",
    "        df_clean.groupby([\"City\", \"Commodity\"])[\"Price\"]\n",
    "        .ffill()\n",
    "        .bfill()\n",
    "    )\n",
    "    \n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93e5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 4: Data Type Conversion\n",
    "\"\"\"\n",
    "\n",
    "def convert_data_types(df: pd.DataFrame, config: ConsolidationConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert columns to appropriate data types.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to convert\n",
    "        config: Configuration object with date format\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with converted data types\n",
    "    \"\"\"\n",
    "    df_converted = df.copy()\n",
    "    \n",
    "    # Convert price column\n",
    "    # Remove commas and convert to numeric\n",
    "    df_converted[\"Price\"] = pd.to_numeric(\n",
    "        df_converted[\"Price\"].astype(str).str.replace(\",\", \"\", regex=False),\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    \n",
    "    # Convert date column\n",
    "    df_converted[\"Date\"] = pd.to_datetime(\n",
    "        df_converted[\"Date\"],\n",
    "        format=config.date_format,\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    \n",
    "    # Convert categorical columns for memory efficiency\n",
    "    categorical_columns = [\"City\", \"Commodity\", \"Year\"]\n",
    "    for col in categorical_columns:\n",
    "        if col in df_converted.columns:\n",
    "            df_converted[col] = df_converted[col].astype(\"category\")\n",
    "    \n",
    "    return df_converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff87639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 5: Commodity Filtering\n",
    "\"\"\"\n",
    "\n",
    "def filter_commodities(df: pd.DataFrame, config: ConsolidationConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter DataFrame to include only specified commodities.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to filter\n",
    "        config: Configuration object with commodity list\n",
    "        \n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    return df[df[\"Commodity\"].isin(config.commodities)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 6: Data Validation\n",
    "\"\"\"\n",
    "\n",
    "def validate_processed_data(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate the processed dataset and return quality metrics.\n",
    "    \n",
    "    Args:\n",
    "        df: Processed DataFrame to validate\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing validation results and quality metrics\n",
    "    \"\"\"\n",
    "    validation_results = {\n",
    "        'total_rows': len(df),\n",
    "        'total_cities': df['City'].nunique(),\n",
    "        'total_commodities': df['Commodity'].nunique(),\n",
    "        'date_range': {\n",
    "            'min_date': df['Date'].min(),\n",
    "            'max_date': df['Date'].max()\n",
    "        },\n",
    "        'missing_values': {\n",
    "            'price_nulls': df['Price'].isnull().sum(),\n",
    "            'date_nulls': df['Date'].isnull().sum()\n",
    "        },\n",
    "        'price_stats': {\n",
    "            'min_price': df['Price'].min(),\n",
    "            'max_price': df['Price'].max(),\n",
    "            'mean_price': df['Price'].mean(),\n",
    "            'negative_prices': (df['Price'] < 0).sum()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Data quality checks\n",
    "    validation_results['quality_issues'] = []\n",
    "    \n",
    "    if validation_results['missing_values']['price_nulls'] > 0:\n",
    "        validation_results['quality_issues'].append(f\"Found {validation_results['missing_values']['price_nulls']} null prices\")\n",
    "    \n",
    "    if validation_results['missing_values']['date_nulls'] > 0:\n",
    "        validation_results['quality_issues'].append(f\"Found {validation_results['missing_values']['date_nulls']} null dates\")\n",
    "    \n",
    "    if validation_results['price_stats']['negative_prices'] > 0:\n",
    "        validation_results['quality_issues'].append(f\"Found {validation_results['price_stats']['negative_prices']} negative prices\")\n",
    "    \n",
    "    return validation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc27538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function 7: Main Consolidation Pipeline\n",
    "\"\"\"\n",
    "\n",
    "def consolidate_food_price_data(config: ConsolidationConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to consolidate all food price data according to configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object specifying what data to process\n",
    "        \n",
    "    Returns:\n",
    "        Consolidated DataFrame\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting data consolidation process\")\n",
    "    \n",
    "    # Discover files\n",
    "    raw_data_path = Path(\"data/raw\")\n",
    "    discovered_files = discover_data_files(raw_data_path, config)\n",
    "    \n",
    "    if not discovered_files:\n",
    "        raise ValueError(\"No files found matching the configuration criteria\")\n",
    "    \n",
    "    # Process each file\n",
    "    all_dataframes = []\n",
    "    \n",
    "    for i, file_info in enumerate(discovered_files, 1):\n",
    "        logger.info(f\"Processing file {i}/{len(discovered_files)}: {file_info['city']} - {file_info['year']}\")\n",
    "        \n",
    "        try:\n",
    "            # Load and clean file\n",
    "            df = load_and_clean_excel_file(file_info, config)\n",
    "            \n",
    "            # Clean missing values\n",
    "            df = clean_missing_values(df, config)\n",
    "            \n",
    "            # Convert data types\n",
    "            df = convert_data_types(df, config)\n",
    "            \n",
    "            # Filter commodities\n",
    "            df = filter_commodities(df, config)\n",
    "            \n",
    "            all_dataframes.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to process {file_info['file_path']}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        raise ValueError(\"No files were successfully processed\")\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    logger.info(\"Concatenating all processed dataframes\")\n",
    "    consolidated_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Final validation\n",
    "    validation_results = validate_processed_data(consolidated_df)\n",
    "    \n",
    "    logger.info(\"Data consolidation completed successfully\")\n",
    "    logger.info(f\"Final dataset: {validation_results['total_rows']} rows, \"\n",
    "               f\"{validation_results['total_cities']} cities, \"\n",
    "               f\"{validation_results['total_commodities']} commodities\")\n",
    "    \n",
    "    return consolidated_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b05353",
   "metadata": {},
   "source": [
    "## Execute Data Consolidation\n",
    "\n",
    "Now let's run the consolidation pipeline and examine the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce78eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 20:06:42,815 - INFO - Starting data consolidation process\n",
      "2025-10-04 20:06:42,816 - INFO - Processing province: Aceh\n",
      "2025-10-04 20:06:42,817 - INFO -   Found 5 files for city: Kota Banda Aceh\n",
      "2025-10-04 20:06:42,818 - INFO -   Found 5 files for city: Kota Lhokseumawe\n",
      "2025-10-04 20:06:42,819 - INFO -   Found 5 files for city: Kota Meulaboh\n",
      "2025-10-04 20:06:42,819 - INFO - Processing province: Banten\n",
      "2025-10-04 20:06:42,820 - INFO -   Found 5 files for city: Kota Cilegon\n",
      "2025-10-04 20:06:42,820 - INFO -   Found 5 files for city: Kota Serang\n",
      "2025-10-04 20:06:42,822 - INFO -   Found 5 files for city: Kota Tangerang\n",
      "2025-10-04 20:06:42,822 - INFO - Processing province: Bengkulu\n",
      "2025-10-04 20:06:42,823 - INFO -   Found 5 files for city: Kota Bengkulu\n",
      "2025-10-04 20:06:42,824 - INFO - Processing province: DI Yogyakarta\n",
      "2025-10-04 20:06:42,824 - INFO -   Found 5 files for city: Kota Yogyakarta\n",
      "2025-10-04 20:06:42,825 - INFO - Processing province: DKI Jakarta\n",
      "2025-10-04 20:06:42,825 - INFO -   Found 5 files for city: Kota Jakarta Pusat\n",
      "2025-10-04 20:06:42,826 - INFO - Processing province: Jambi\n",
      "2025-10-04 20:06:42,827 - INFO -   Found 5 files for city: Kab. Bungo\n",
      "2025-10-04 20:06:42,828 - INFO -   Found 5 files for city: Kota Jambi\n",
      "2025-10-04 20:06:42,828 - INFO - Processing province: Jawa Barat\n",
      "2025-10-04 20:06:42,829 - INFO -   Found 5 files for city: Kab. Cirebon\n",
      "2025-10-04 20:06:42,829 - INFO -   Found 5 files for city: Kab. Tasikmalaya\n",
      "2025-10-04 20:06:42,830 - INFO -   Found 5 files for city: Kota Bandung\n",
      "2025-10-04 20:06:42,831 - INFO -   Found 5 files for city: Kota Bekasi\n",
      "2025-10-04 20:06:42,832 - INFO -   Found 5 files for city: Kota Bogor\n",
      "2025-10-04 20:06:42,833 - INFO -   Found 5 files for city: Kota Cirebon\n",
      "2025-10-04 20:06:42,834 - INFO -   Found 5 files for city: Kota Depok\n",
      "2025-10-04 20:06:42,834 - INFO -   Found 5 files for city: Kota Sukabumi\n",
      "2025-10-04 20:06:42,835 - INFO -   Found 5 files for city: Kota Tasikmalaya\n",
      "2025-10-04 20:06:42,835 - INFO - Processing province: Jawa Tengah\n",
      "2025-10-04 20:06:42,836 - INFO -   Found 5 files for city: Kab. Banyumas\n",
      "2025-10-04 20:06:42,837 - INFO -   Found 5 files for city: Kab. Boyolali\n",
      "2025-10-04 20:06:42,837 - INFO -   Found 5 files for city: Kab. Cilacap\n",
      "2025-10-04 20:06:42,838 - INFO -   Found 5 files for city: Kab. Karanganyar\n",
      "2025-10-04 20:06:42,839 - INFO -   Found 5 files for city: Kab. Klaten\n",
      "2025-10-04 20:06:42,840 - INFO -   Found 5 files for city: Kab. Kudus\n",
      "2025-10-04 20:06:42,840 - INFO -   Found 5 files for city: Kab. Sragen\n",
      "2025-10-04 20:06:42,841 - INFO -   Found 5 files for city: Kab. Sukoharjo\n",
      "2025-10-04 20:06:42,841 - INFO -   Found 5 files for city: Kab. Wonogiri\n",
      "2025-10-04 20:06:42,842 - INFO -   Found 5 files for city: Kota Semarang\n",
      "2025-10-04 20:06:42,843 - INFO -   Found 5 files for city: Kota Surakarta (Solo)\n",
      "2025-10-04 20:06:42,844 - INFO -   Found 5 files for city: Kota Tegal\n",
      "2025-10-04 20:06:42,845 - INFO - Processing province: Jawa Timur\n",
      "2025-10-04 20:06:42,845 - INFO -   Found 5 files for city: Kab. Banyuwangi\n",
      "2025-10-04 20:06:42,846 - INFO -   Found 5 files for city: Kab. Jember\n",
      "2025-10-04 20:06:42,847 - INFO -   Found 5 files for city: Kab. Sumenep\n",
      "2025-10-04 20:06:42,848 - INFO -   Found 5 files for city: Kota Blitar\n",
      "2025-10-04 20:06:42,848 - INFO -   Found 5 files for city: Kota Kediri\n",
      "2025-10-04 20:06:42,850 - INFO -   Found 5 files for city: Kota Madiun\n",
      "2025-10-04 20:06:42,850 - INFO -   Found 5 files for city: Kota Malang\n",
      "2025-10-04 20:06:42,851 - INFO -   Found 5 files for city: Kota Probolinggo\n",
      "2025-10-04 20:06:42,852 - INFO -   Found 5 files for city: Kota Surabaya\n",
      "2025-10-04 20:06:42,852 - INFO - Processing province: Kalimantan Barat\n",
      "2025-10-04 20:06:42,853 - INFO -   Found 5 files for city: Kota Pontianak\n",
      "2025-10-04 20:06:42,853 - INFO -   Found 5 files for city: Kota Singkawang\n",
      "2025-10-04 20:06:42,854 - INFO - Processing province: Kalimantan Selatan\n",
      "2025-10-04 20:06:42,854 - INFO -   Found 5 files for city: Kota Banjarmasin\n",
      "2025-10-04 20:06:42,855 - INFO -   Found 5 files for city: Kota Tanjung\n",
      "2025-10-04 20:06:42,856 - INFO - Processing province: Kalimantan Tengah\n",
      "2025-10-04 20:06:42,856 - INFO -   Found 5 files for city: Kota Palangkaraya\n",
      "2025-10-04 20:06:42,857 - INFO -   Found 5 files for city: Kota Sampit\n",
      "2025-10-04 20:06:42,858 - INFO - Processing province: Kalimantan Timur\n",
      "2025-10-04 20:06:42,858 - INFO -   Found 5 files for city: Kota Balikpapan\n",
      "2025-10-04 20:06:42,859 - INFO -   Found 5 files for city: Kota Bontang\n",
      "2025-10-04 20:06:42,859 - INFO -   Found 5 files for city: Kota Samarinda\n",
      "2025-10-04 20:06:42,860 - INFO - Processing province: Kalimantan Utara\n",
      "2025-10-04 20:06:42,860 - INFO -   Found 5 files for city: Kab. Bulungan\n",
      "2025-10-04 20:06:42,861 - INFO -   Found 5 files for city: Kota Tarakan\n",
      "2025-10-04 20:06:42,861 - INFO - Processing province: Kepulauan Bangka Belitung\n",
      "2025-10-04 20:06:42,862 - INFO -   Found 5 files for city: Kota Pangkal Pinang\n",
      "2025-10-04 20:06:42,863 - INFO -   Found 5 files for city: Kota Tanjung Pandan\n",
      "2025-10-04 20:06:42,863 - INFO - Processing province: Kepulauan Riau\n",
      "2025-10-04 20:06:42,864 - INFO -   Found 5 files for city: Kota Batam\n",
      "2025-10-04 20:06:42,865 - INFO -   Found 5 files for city: Kota Tanjung Pinang\n",
      "2025-10-04 20:06:42,865 - INFO - Processing province: Lampung\n",
      "2025-10-04 20:06:42,866 - INFO -   Found 5 files for city: Kota Bandar Lampung\n",
      "2025-10-04 20:06:42,866 - INFO -   Found 5 files for city: Kota Metro\n",
      "2025-10-04 20:06:42,866 - INFO - Processing province: Riau\n",
      "2025-10-04 20:06:42,867 - INFO -   Found 5 files for city: Kota Dumai\n",
      "2025-10-04 20:06:42,868 - INFO -   Found 5 files for city: Kota Pekanbaru\n",
      "2025-10-04 20:06:42,868 - INFO -   Found 5 files for city: Kota Tembilahan\n",
      "2025-10-04 20:06:42,869 - INFO - Processing province: Sumatera Barat\n",
      "2025-10-04 20:06:42,869 - INFO -   Found 5 files for city: Kota Bukittinggi\n",
      "2025-10-04 20:06:42,870 - INFO -   Found 5 files for city: Kota Padang\n",
      "2025-10-04 20:06:42,870 - INFO - Processing province: Sumatera Selatan\n",
      "2025-10-04 20:06:42,871 - INFO -   Found 5 files for city: Kota Lubuk Linggau\n",
      "2025-10-04 20:06:42,872 - INFO -   Found 5 files for city: Kota Palembang\n",
      "2025-10-04 20:06:42,872 - INFO - Processing province: Sumatera Utara\n",
      "2025-10-04 20:06:42,873 - INFO -   Found 5 files for city: Kota Medan\n",
      "2025-10-04 20:06:42,873 - INFO -   Found 5 files for city: Kota Padang Sidempuan\n",
      "2025-10-04 20:06:42,874 - INFO -   Found 5 files for city: Kota Pematang Siantar\n",
      "2025-10-04 20:06:42,875 - INFO -   Found 5 files for city: Kota Sibolga\n",
      "2025-10-04 20:06:42,875 - INFO - Total files discovered: 345\n",
      "2025-10-04 20:06:42,876 - INFO - Processing file 1/345: Kota Banda Aceh - 2020\n",
      "2025-10-04 20:06:43,193 - INFO - Processing file 2/345: Kota Banda Aceh - 2021\n",
      "2025-10-04 20:06:43,271 - INFO - Processing file 3/345: Kota Banda Aceh - 2022\n",
      "2025-10-04 20:06:43,341 - INFO - Processing file 4/345: Kota Banda Aceh - 2023\n",
      "2025-10-04 20:06:43,413 - INFO - Processing file 5/345: Kota Banda Aceh - 2024\n",
      "2025-10-04 20:06:43,484 - INFO - Processing file 6/345: Kota Lhokseumawe - 2020\n",
      "2025-10-04 20:06:43,560 - INFO - Processing file 7/345: Kota Lhokseumawe - 2021\n",
      "2025-10-04 20:06:43,634 - INFO - Processing file 8/345: Kota Lhokseumawe - 2022\n",
      "2025-10-04 20:06:43,711 - INFO - Processing file 9/345: Kota Lhokseumawe - 2023\n",
      "2025-10-04 20:06:43,839 - INFO - Processing file 10/345: Kota Lhokseumawe - 2024\n",
      "2025-10-04 20:06:43,911 - INFO - Processing file 11/345: Kota Meulaboh - 2020\n",
      "2025-10-04 20:06:43,991 - INFO - Processing file 12/345: Kota Meulaboh - 2021\n",
      "2025-10-04 20:06:44,068 - INFO - Processing file 13/345: Kota Meulaboh - 2022\n",
      "2025-10-04 20:06:44,146 - INFO - Processing file 14/345: Kota Meulaboh - 2023\n",
      "2025-10-04 20:06:44,220 - INFO - Processing file 15/345: Kota Meulaboh - 2024\n",
      "2025-10-04 20:06:44,295 - INFO - Processing file 16/345: Kota Cilegon - 2020\n",
      "2025-10-04 20:06:44,368 - INFO - Processing file 17/345: Kota Cilegon - 2021\n",
      "2025-10-04 20:06:44,498 - INFO - Processing file 18/345: Kota Cilegon - 2022\n",
      "2025-10-04 20:06:44,574 - INFO - Processing file 19/345: Kota Cilegon - 2023\n",
      "2025-10-04 20:06:44,648 - INFO - Processing file 20/345: Kota Cilegon - 2024\n",
      "2025-10-04 20:06:44,724 - INFO - Processing file 21/345: Kota Serang - 2020\n",
      "2025-10-04 20:06:44,801 - INFO - Processing file 22/345: Kota Serang - 2021\n",
      "2025-10-04 20:06:44,877 - INFO - Processing file 23/345: Kota Serang - 2022\n",
      "2025-10-04 20:06:44,953 - INFO - Processing file 24/345: Kota Serang - 2023\n",
      "2025-10-04 20:06:45,028 - INFO - Processing file 25/345: Kota Serang - 2024\n",
      "2025-10-04 20:06:45,158 - INFO - Processing file 26/345: Kota Tangerang - 2020\n",
      "2025-10-04 20:06:45,234 - INFO - Processing file 27/345: Kota Tangerang - 2021\n",
      "2025-10-04 20:06:45,313 - INFO - Processing file 28/345: Kota Tangerang - 2022\n",
      "2025-10-04 20:06:45,390 - INFO - Processing file 29/345: Kota Tangerang - 2023\n",
      "2025-10-04 20:06:45,466 - INFO - Processing file 30/345: Kota Tangerang - 2024\n",
      "2025-10-04 20:06:45,545 - INFO - Processing file 31/345: Kota Bengkulu - 2020\n",
      "2025-10-04 20:06:45,620 - INFO - Processing file 32/345: Kota Bengkulu - 2021\n",
      "2025-10-04 20:06:45,770 - INFO - Processing file 33/345: Kota Bengkulu - 2022\n",
      "2025-10-04 20:06:45,858 - INFO - Processing file 34/345: Kota Bengkulu - 2023\n",
      "2025-10-04 20:06:45,936 - INFO - Processing file 35/345: Kota Bengkulu - 2024\n",
      "2025-10-04 20:06:46,018 - INFO - Processing file 36/345: Kota Yogyakarta - 2020\n",
      "2025-10-04 20:06:46,095 - INFO - Processing file 37/345: Kota Yogyakarta - 2021\n",
      "2025-10-04 20:06:46,174 - INFO - Processing file 38/345: Kota Yogyakarta - 2022\n",
      "2025-10-04 20:06:46,248 - INFO - Processing file 39/345: Kota Yogyakarta - 2023\n",
      "2025-10-04 20:06:46,372 - INFO - Processing file 40/345: Kota Yogyakarta - 2024\n",
      "2025-10-04 20:06:46,445 - INFO - Processing file 41/345: Kota Jakarta Pusat - 2020\n",
      "2025-10-04 20:06:46,523 - INFO - Processing file 42/345: Kota Jakarta Pusat - 2021\n",
      "2025-10-04 20:06:46,599 - INFO - Processing file 43/345: Kota Jakarta Pusat - 2022\n",
      "2025-10-04 20:06:46,676 - INFO - Processing file 44/345: Kota Jakarta Pusat - 2023\n",
      "2025-10-04 20:06:46,751 - INFO - Processing file 45/345: Kota Jakarta Pusat - 2024\n",
      "2025-10-04 20:06:46,827 - INFO - Processing file 46/345: Kab. Bungo - 2020\n",
      "2025-10-04 20:06:46,900 - INFO - Processing file 47/345: Kab. Bungo - 2021\n",
      "2025-10-04 20:06:46,974 - INFO - Processing file 48/345: Kab. Bungo - 2022\n",
      "2025-10-04 20:06:47,100 - INFO - Processing file 49/345: Kab. Bungo - 2023\n",
      "2025-10-04 20:06:47,172 - INFO - Processing file 50/345: Kab. Bungo - 2024\n",
      "2025-10-04 20:06:47,246 - INFO - Processing file 51/345: Kota Jambi - 2020\n",
      "2025-10-04 20:06:47,320 - INFO - Processing file 52/345: Kota Jambi - 2021\n",
      "2025-10-04 20:06:47,394 - INFO - Processing file 53/345: Kota Jambi - 2022\n",
      "2025-10-04 20:06:47,471 - INFO - Processing file 54/345: Kota Jambi - 2023\n",
      "2025-10-04 20:06:47,543 - INFO - Processing file 55/345: Kota Jambi - 2024\n",
      "2025-10-04 20:06:47,617 - INFO - Processing file 56/345: Kab. Cirebon - 2020\n",
      "2025-10-04 20:06:47,749 - INFO - Processing file 57/345: Kab. Cirebon - 2021\n",
      "2025-10-04 20:06:47,825 - INFO - Processing file 58/345: Kab. Cirebon - 2022\n",
      "2025-10-04 20:06:47,904 - INFO - Processing file 59/345: Kab. Cirebon - 2023\n",
      "2025-10-04 20:06:47,980 - INFO - Processing file 60/345: Kab. Cirebon - 2024\n",
      "2025-10-04 20:06:48,058 - INFO - Processing file 61/345: Kab. Tasikmalaya - 2020\n",
      "2025-10-04 20:06:48,136 - INFO - Processing file 62/345: Kab. Tasikmalaya - 2021\n",
      "2025-10-04 20:06:48,216 - INFO - Processing file 63/345: Kab. Tasikmalaya - 2022\n",
      "2025-10-04 20:06:48,351 - INFO - Processing file 64/345: Kab. Tasikmalaya - 2023\n",
      "2025-10-04 20:06:48,430 - INFO - Processing file 65/345: Kab. Tasikmalaya - 2024\n",
      "2025-10-04 20:06:48,510 - INFO - Processing file 66/345: Kota Bandung - 2020\n",
      "2025-10-04 20:06:48,586 - INFO - Processing file 67/345: Kota Bandung - 2021\n",
      "2025-10-04 20:06:48,658 - INFO - Processing file 68/345: Kota Bandung - 2022\n",
      "2025-10-04 20:06:48,732 - INFO - Processing file 69/345: Kota Bandung - 2023\n",
      "2025-10-04 20:06:48,806 - INFO - Processing file 70/345: Kota Bandung - 2024\n",
      "2025-10-04 20:06:48,878 - INFO - Processing file 71/345: Kota Bekasi - 2020\n",
      "2025-10-04 20:06:49,007 - INFO - Processing file 72/345: Kota Bekasi - 2021\n",
      "2025-10-04 20:06:49,082 - INFO - Processing file 73/345: Kota Bekasi - 2022\n",
      "2025-10-04 20:06:49,156 - INFO - Processing file 74/345: Kota Bekasi - 2023\n",
      "2025-10-04 20:06:49,240 - INFO - Processing file 75/345: Kota Bekasi - 2024\n",
      "2025-10-04 20:06:49,314 - INFO - Processing file 76/345: Kota Bogor - 2020\n",
      "2025-10-04 20:06:49,392 - INFO - Processing file 77/345: Kota Bogor - 2021\n",
      "2025-10-04 20:06:49,467 - INFO - Processing file 78/345: Kota Bogor - 2022\n",
      "2025-10-04 20:06:49,603 - INFO - Processing file 79/345: Kota Bogor - 2023\n",
      "2025-10-04 20:06:49,686 - INFO - Processing file 80/345: Kota Bogor - 2024\n",
      "2025-10-04 20:06:49,770 - INFO - Processing file 81/345: Kota Cirebon - 2020\n",
      "2025-10-04 20:06:49,855 - INFO - Processing file 82/345: Kota Cirebon - 2021\n",
      "2025-10-04 20:06:49,945 - INFO - Processing file 83/345: Kota Cirebon - 2022\n",
      "2025-10-04 20:06:50,033 - INFO - Processing file 84/345: Kota Cirebon - 2023\n",
      "2025-10-04 20:06:50,111 - INFO - Processing file 85/345: Kota Cirebon - 2024\n",
      "2025-10-04 20:06:50,190 - INFO - Processing file 86/345: Kota Depok - 2020\n",
      "2025-10-04 20:06:50,326 - INFO - Processing file 87/345: Kota Depok - 2021\n",
      "2025-10-04 20:06:50,403 - INFO - Processing file 88/345: Kota Depok - 2022\n",
      "2025-10-04 20:06:50,485 - INFO - Processing file 89/345: Kota Depok - 2023\n",
      "2025-10-04 20:06:50,562 - INFO - Processing file 90/345: Kota Depok - 2024\n",
      "2025-10-04 20:06:50,642 - INFO - Processing file 91/345: Kota Sukabumi - 2020\n",
      "2025-10-04 20:06:50,722 - INFO - Processing file 92/345: Kota Sukabumi - 2021\n",
      "2025-10-04 20:06:50,802 - INFO - Processing file 93/345: Kota Sukabumi - 2022\n",
      "2025-10-04 20:06:50,883 - INFO - Processing file 94/345: Kota Sukabumi - 2023\n",
      "2025-10-04 20:06:51,017 - INFO - Processing file 95/345: Kota Sukabumi - 2024\n",
      "2025-10-04 20:06:51,096 - INFO - Processing file 96/345: Kota Tasikmalaya - 2020\n",
      "2025-10-04 20:06:51,171 - INFO - Processing file 97/345: Kota Tasikmalaya - 2021\n",
      "2025-10-04 20:06:51,250 - INFO - Processing file 98/345: Kota Tasikmalaya - 2022\n",
      "2025-10-04 20:06:51,329 - INFO - Processing file 99/345: Kota Tasikmalaya - 2023\n",
      "2025-10-04 20:06:51,408 - INFO - Processing file 100/345: Kota Tasikmalaya - 2024\n",
      "2025-10-04 20:06:51,485 - INFO - Processing file 101/345: Kab. Banyumas - 2020\n",
      "2025-10-04 20:06:51,617 - INFO - Processing file 102/345: Kab. Banyumas - 2021\n",
      "2025-10-04 20:06:51,690 - INFO - Processing file 103/345: Kab. Banyumas - 2022\n",
      "2025-10-04 20:06:51,766 - INFO - Processing file 104/345: Kab. Banyumas - 2023\n",
      "2025-10-04 20:06:51,839 - INFO - Processing file 105/345: Kab. Banyumas - 2024\n",
      "2025-10-04 20:06:51,912 - INFO - Processing file 106/345: Kab. Boyolali - 2020\n",
      "2025-10-04 20:06:51,991 - INFO - Processing file 107/345: Kab. Boyolali - 2021\n",
      "2025-10-04 20:06:52,068 - INFO - Processing file 108/345: Kab. Boyolali - 2022\n",
      "2025-10-04 20:06:52,199 - INFO - Processing file 109/345: Kab. Boyolali - 2023\n",
      "2025-10-04 20:06:52,277 - INFO - Processing file 110/345: Kab. Boyolali - 2024\n",
      "2025-10-04 20:06:52,358 - INFO - Processing file 111/345: Kab. Cilacap - 2020\n",
      "2025-10-04 20:06:52,435 - INFO - Processing file 112/345: Kab. Cilacap - 2021\n",
      "2025-10-04 20:06:52,513 - INFO - Processing file 113/345: Kab. Cilacap - 2022\n",
      "2025-10-04 20:06:52,591 - INFO - Processing file 114/345: Kab. Cilacap - 2023\n",
      "2025-10-04 20:06:52,667 - INFO - Processing file 115/345: Kab. Cilacap - 2024\n",
      "2025-10-04 20:06:52,748 - INFO - Processing file 116/345: Kab. Karanganyar - 2020\n",
      "2025-10-04 20:06:52,824 - INFO - Processing file 117/345: Kab. Karanganyar - 2021\n",
      "2025-10-04 20:06:52,958 - INFO - Processing file 118/345: Kab. Karanganyar - 2022\n",
      "2025-10-04 20:06:53,036 - INFO - Processing file 119/345: Kab. Karanganyar - 2023\n",
      "2025-10-04 20:06:53,113 - INFO - Processing file 120/345: Kab. Karanganyar - 2024\n",
      "2025-10-04 20:06:53,191 - INFO - Processing file 121/345: Kab. Klaten - 2020\n",
      "2025-10-04 20:06:53,269 - INFO - Processing file 122/345: Kab. Klaten - 2021\n",
      "2025-10-04 20:06:53,348 - INFO - Processing file 123/345: Kab. Klaten - 2022\n",
      "2025-10-04 20:06:53,427 - INFO - Processing file 124/345: Kab. Klaten - 2023\n",
      "2025-10-04 20:06:53,508 - INFO - Processing file 125/345: Kab. Klaten - 2024\n",
      "2025-10-04 20:06:53,642 - INFO - Processing file 126/345: Kab. Kudus - 2020\n",
      "2025-10-04 20:06:53,719 - INFO - Processing file 127/345: Kab. Kudus - 2021\n",
      "2025-10-04 20:06:53,798 - INFO - Processing file 128/345: Kab. Kudus - 2022\n",
      "2025-10-04 20:06:53,877 - INFO - Processing file 129/345: Kab. Kudus - 2023\n",
      "2025-10-04 20:06:53,957 - INFO - Processing file 130/345: Kab. Kudus - 2024\n",
      "2025-10-04 20:06:54,036 - INFO - Processing file 131/345: Kab. Sragen - 2020\n",
      "2025-10-04 20:06:54,115 - INFO - Processing file 132/345: Kab. Sragen - 2021\n",
      "2025-10-04 20:06:54,252 - INFO - Processing file 133/345: Kab. Sragen - 2022\n",
      "2025-10-04 20:06:54,328 - INFO - Processing file 134/345: Kab. Sragen - 2023\n",
      "2025-10-04 20:06:54,410 - INFO - Processing file 135/345: Kab. Sragen - 2024\n",
      "2025-10-04 20:06:54,487 - INFO - Processing file 136/345: Kab. Sukoharjo - 2020\n",
      "2025-10-04 20:06:54,567 - INFO - Processing file 137/345: Kab. Sukoharjo - 2021\n",
      "2025-10-04 20:06:54,648 - INFO - Processing file 138/345: Kab. Sukoharjo - 2022\n",
      "2025-10-04 20:06:54,727 - INFO - Processing file 139/345: Kab. Sukoharjo - 2023\n",
      "2025-10-04 20:06:54,805 - INFO - Processing file 140/345: Kab. Sukoharjo - 2024\n",
      "2025-10-04 20:06:54,943 - INFO - Processing file 141/345: Kab. Wonogiri - 2020\n",
      "2025-10-04 20:06:55,022 - INFO - Processing file 142/345: Kab. Wonogiri - 2021\n",
      "2025-10-04 20:06:55,105 - INFO - Processing file 143/345: Kab. Wonogiri - 2022\n",
      "2025-10-04 20:06:55,211 - INFO - Processing file 144/345: Kab. Wonogiri - 2023\n",
      "2025-10-04 20:06:55,288 - INFO - Processing file 145/345: Kab. Wonogiri - 2024\n",
      "2025-10-04 20:06:55,370 - INFO - Processing file 146/345: Kota Semarang - 2020\n",
      "2025-10-04 20:06:55,449 - INFO - Processing file 147/345: Kota Semarang - 2021\n",
      "2025-10-04 20:06:55,585 - INFO - Processing file 148/345: Kota Semarang - 2022\n",
      "2025-10-04 20:06:55,667 - INFO - Processing file 149/345: Kota Semarang - 2023\n",
      "2025-10-04 20:06:55,745 - INFO - Processing file 150/345: Kota Semarang - 2024\n",
      "2025-10-04 20:06:55,828 - INFO - Processing file 151/345: Kota Surakarta (Solo) - 2020\n",
      "2025-10-04 20:06:55,904 - INFO - Processing file 152/345: Kota Surakarta (Solo) - 2021\n",
      "2025-10-04 20:06:55,982 - INFO - Processing file 153/345: Kota Surakarta (Solo) - 2022\n",
      "2025-10-04 20:06:56,065 - INFO - Processing file 154/345: Kota Surakarta (Solo) - 2023\n",
      "2025-10-04 20:06:56,152 - INFO - Processing file 155/345: Kota Surakarta (Solo) - 2024\n",
      "2025-10-04 20:06:56,296 - INFO - Processing file 156/345: Kota Tegal - 2020\n",
      "2025-10-04 20:06:56,389 - INFO - Processing file 157/345: Kota Tegal - 2021\n",
      "2025-10-04 20:06:56,469 - INFO - Processing file 158/345: Kota Tegal - 2022\n",
      "2025-10-04 20:06:56,555 - INFO - Processing file 159/345: Kota Tegal - 2023\n",
      "2025-10-04 20:06:56,636 - INFO - Processing file 160/345: Kota Tegal - 2024\n",
      "2025-10-04 20:06:56,717 - INFO - Processing file 161/345: Kab. Banyuwangi - 2020\n",
      "2025-10-04 20:06:56,790 - INFO - Processing file 162/345: Kab. Banyuwangi - 2021\n",
      "2025-10-04 20:06:56,861 - INFO - Processing file 163/345: Kab. Banyuwangi - 2022\n",
      "2025-10-04 20:06:56,988 - INFO - Processing file 164/345: Kab. Banyuwangi - 2023\n",
      "2025-10-04 20:06:57,062 - INFO - Processing file 165/345: Kab. Banyuwangi - 2024\n",
      "2025-10-04 20:06:57,142 - INFO - Processing file 166/345: Kab. Jember - 2020\n",
      "2025-10-04 20:06:57,218 - INFO - Processing file 167/345: Kab. Jember - 2021\n",
      "2025-10-04 20:06:57,293 - INFO - Processing file 168/345: Kab. Jember - 2022\n",
      "2025-10-04 20:06:57,371 - INFO - Processing file 169/345: Kab. Jember - 2023\n",
      "2025-10-04 20:06:57,445 - INFO - Processing file 170/345: Kab. Jember - 2024\n",
      "2025-10-04 20:06:57,521 - INFO - Processing file 171/345: Kab. Sumenep - 2020\n",
      "2025-10-04 20:06:57,659 - INFO - Processing file 172/345: Kab. Sumenep - 2021\n",
      "2025-10-04 20:06:57,736 - INFO - Processing file 173/345: Kab. Sumenep - 2022\n",
      "2025-10-04 20:06:57,816 - INFO - Processing file 174/345: Kab. Sumenep - 2023\n",
      "2025-10-04 20:06:57,897 - INFO - Processing file 175/345: Kab. Sumenep - 2024\n",
      "2025-10-04 20:06:57,975 - INFO - Processing file 176/345: Kota Blitar - 2020\n",
      "2025-10-04 20:06:58,051 - INFO - Processing file 177/345: Kota Blitar - 2021\n",
      "2025-10-04 20:06:58,126 - INFO - Processing file 178/345: Kota Blitar - 2022\n",
      "2025-10-04 20:06:58,201 - INFO - Processing file 179/345: Kota Blitar - 2023\n",
      "2025-10-04 20:06:58,338 - INFO - Processing file 180/345: Kota Blitar - 2024\n",
      "2025-10-04 20:06:58,416 - INFO - Processing file 181/345: Kota Kediri - 2020\n",
      "2025-10-04 20:06:58,492 - INFO - Processing file 182/345: Kota Kediri - 2021\n",
      "2025-10-04 20:06:58,570 - INFO - Processing file 183/345: Kota Kediri - 2022\n",
      "2025-10-04 20:06:58,646 - INFO - Processing file 184/345: Kota Kediri - 2023\n",
      "2025-10-04 20:06:58,723 - INFO - Processing file 185/345: Kota Kediri - 2024\n",
      "2025-10-04 20:06:58,801 - INFO - Processing file 186/345: Kota Madiun - 2020\n",
      "2025-10-04 20:06:58,877 - INFO - Processing file 187/345: Kota Madiun - 2021\n",
      "2025-10-04 20:06:59,009 - INFO - Processing file 188/345: Kota Madiun - 2022\n",
      "2025-10-04 20:06:59,089 - INFO - Processing file 189/345: Kota Madiun - 2023\n",
      "2025-10-04 20:06:59,165 - INFO - Processing file 190/345: Kota Madiun - 2024\n",
      "2025-10-04 20:06:59,242 - INFO - Processing file 191/345: Kota Malang - 2020\n",
      "2025-10-04 20:06:59,320 - INFO - Processing file 192/345: Kota Malang - 2021\n",
      "2025-10-04 20:06:59,397 - INFO - Processing file 193/345: Kota Malang - 2022\n",
      "2025-10-04 20:06:59,475 - INFO - Processing file 194/345: Kota Malang - 2023\n",
      "2025-10-04 20:06:59,608 - INFO - Processing file 195/345: Kota Malang - 2024\n",
      "2025-10-04 20:06:59,686 - INFO - Processing file 196/345: Kota Probolinggo - 2020\n",
      "2025-10-04 20:06:59,763 - INFO - Processing file 197/345: Kota Probolinggo - 2021\n",
      "2025-10-04 20:06:59,843 - INFO - Processing file 198/345: Kota Probolinggo - 2022\n",
      "2025-10-04 20:06:59,921 - INFO - Processing file 199/345: Kota Probolinggo - 2023\n",
      "2025-10-04 20:06:59,999 - INFO - Processing file 200/345: Kota Probolinggo - 2024\n",
      "2025-10-04 20:07:00,081 - INFO - Processing file 201/345: Kota Surabaya - 2020\n",
      "2025-10-04 20:07:00,219 - INFO - Processing file 202/345: Kota Surabaya - 2021\n",
      "2025-10-04 20:07:00,298 - INFO - Processing file 203/345: Kota Surabaya - 2022\n",
      "2025-10-04 20:07:00,380 - INFO - Processing file 204/345: Kota Surabaya - 2023\n",
      "2025-10-04 20:07:00,460 - INFO - Processing file 205/345: Kota Surabaya - 2024\n",
      "2025-10-04 20:07:00,537 - INFO - Processing file 206/345: Kota Pontianak - 2020\n",
      "2025-10-04 20:07:00,617 - INFO - Processing file 207/345: Kota Pontianak - 2021\n",
      "2025-10-04 20:07:00,696 - INFO - Processing file 208/345: Kota Pontianak - 2022\n",
      "2025-10-04 20:07:00,778 - INFO - Processing file 209/345: Kota Pontianak - 2023\n",
      "2025-10-04 20:07:00,858 - INFO - Processing file 210/345: Kota Pontianak - 2024\n",
      "2025-10-04 20:07:01,024 - INFO - Processing file 211/345: Kota Singkawang - 2020\n",
      "2025-10-04 20:07:01,095 - INFO - Processing file 212/345: Kota Singkawang - 2021\n",
      "2025-10-04 20:07:01,169 - INFO - Processing file 213/345: Kota Singkawang - 2022\n",
      "2025-10-04 20:07:01,241 - INFO - Processing file 214/345: Kota Singkawang - 2023\n",
      "2025-10-04 20:07:01,312 - INFO - Processing file 215/345: Kota Singkawang - 2024\n",
      "2025-10-04 20:07:01,385 - INFO - Processing file 216/345: Kota Banjarmasin - 2020\n",
      "2025-10-04 20:07:01,462 - INFO - Processing file 217/345: Kota Banjarmasin - 2021\n",
      "2025-10-04 20:07:01,558 - INFO - Processing file 218/345: Kota Banjarmasin - 2022\n",
      "2025-10-04 20:07:01,697 - INFO - Processing file 219/345: Kota Banjarmasin - 2023\n",
      "2025-10-04 20:07:01,773 - INFO - Processing file 220/345: Kota Banjarmasin - 2024\n",
      "2025-10-04 20:07:01,886 - INFO - Processing file 221/345: Kota Tanjung - 2020\n",
      "2025-10-04 20:07:01,965 - INFO - Processing file 222/345: Kota Tanjung - 2021\n",
      "2025-10-04 20:07:02,045 - INFO - Processing file 223/345: Kota Tanjung - 2022\n",
      "2025-10-04 20:07:02,122 - INFO - Processing file 224/345: Kota Tanjung - 2023\n",
      "2025-10-04 20:07:02,200 - INFO - Processing file 225/345: Kota Tanjung - 2024\n",
      "2025-10-04 20:07:02,336 - INFO - Processing file 226/345: Kota Palangkaraya - 2020\n",
      "2025-10-04 20:07:02,412 - INFO - Processing file 227/345: Kota Palangkaraya - 2021\n",
      "2025-10-04 20:07:02,488 - INFO - Processing file 228/345: Kota Palangkaraya - 2022\n",
      "2025-10-04 20:07:02,563 - INFO - Processing file 229/345: Kota Palangkaraya - 2023\n",
      "2025-10-04 20:07:02,637 - INFO - Processing file 230/345: Kota Palangkaraya - 2024\n",
      "2025-10-04 20:07:02,710 - INFO - Processing file 231/345: Kota Sampit - 2020\n",
      "2025-10-04 20:07:02,787 - INFO - Processing file 232/345: Kota Sampit - 2021\n",
      "2025-10-04 20:07:02,863 - INFO - Processing file 233/345: Kota Sampit - 2022\n",
      "2025-10-04 20:07:02,938 - INFO - Processing file 234/345: Kota Sampit - 2023\n",
      "2025-10-04 20:07:03,074 - INFO - Processing file 235/345: Kota Sampit - 2024\n",
      "2025-10-04 20:07:03,151 - INFO - Processing file 236/345: Kota Balikpapan - 2020\n",
      "2025-10-04 20:07:03,227 - INFO - Processing file 237/345: Kota Balikpapan - 2021\n",
      "2025-10-04 20:07:03,301 - INFO - Processing file 238/345: Kota Balikpapan - 2022\n",
      "2025-10-04 20:07:03,379 - INFO - Processing file 239/345: Kota Balikpapan - 2023\n",
      "2025-10-04 20:07:03,454 - INFO - Processing file 240/345: Kota Balikpapan - 2024\n",
      "2025-10-04 20:07:03,529 - INFO - Processing file 241/345: Kota Bontang - 2020\n",
      "2025-10-04 20:07:03,605 - INFO - Processing file 242/345: Kota Bontang - 2021\n",
      "2025-10-04 20:07:03,679 - INFO - Processing file 243/345: Kota Bontang - 2022\n",
      "2025-10-04 20:07:03,816 - INFO - Processing file 244/345: Kota Bontang - 2023\n",
      "2025-10-04 20:07:03,892 - INFO - Processing file 245/345: Kota Bontang - 2024\n",
      "2025-10-04 20:07:03,973 - INFO - Processing file 246/345: Kota Samarinda - 2020\n",
      "2025-10-04 20:07:04,052 - INFO - Processing file 247/345: Kota Samarinda - 2021\n",
      "2025-10-04 20:07:04,129 - INFO - Processing file 248/345: Kota Samarinda - 2022\n",
      "2025-10-04 20:07:04,206 - INFO - Processing file 249/345: Kota Samarinda - 2023\n",
      "2025-10-04 20:07:04,285 - INFO - Processing file 250/345: Kota Samarinda - 2024\n",
      "2025-10-04 20:07:04,363 - INFO - Processing file 251/345: Kab. Bulungan - 2020\n",
      "2025-10-04 20:07:04,494 - INFO - Processing file 252/345: Kab. Bulungan - 2021\n",
      "2025-10-04 20:07:04,565 - INFO - Processing file 253/345: Kab. Bulungan - 2022\n",
      "2025-10-04 20:07:04,639 - INFO - Processing file 254/345: Kab. Bulungan - 2023\n",
      "2025-10-04 20:07:04,712 - INFO - Processing file 255/345: Kab. Bulungan - 2024\n",
      "2025-10-04 20:07:04,783 - INFO - Processing file 256/345: Kota Tarakan - 2020\n",
      "2025-10-04 20:07:04,857 - INFO - Processing file 257/345: Kota Tarakan - 2021\n",
      "2025-10-04 20:07:04,932 - INFO - Processing file 258/345: Kota Tarakan - 2022\n",
      "2025-10-04 20:07:05,010 - INFO - Processing file 259/345: Kota Tarakan - 2023\n",
      "2025-10-04 20:07:05,086 - INFO - Processing file 260/345: Kota Tarakan - 2024\n",
      "2025-10-04 20:07:05,227 - INFO - Processing file 261/345: Kota Pangkal Pinang - 2020\n",
      "2025-10-04 20:07:05,301 - INFO - Processing file 262/345: Kota Pangkal Pinang - 2021\n",
      "2025-10-04 20:07:05,380 - INFO - Processing file 263/345: Kota Pangkal Pinang - 2022\n",
      "2025-10-04 20:07:05,466 - INFO - Processing file 264/345: Kota Pangkal Pinang - 2023\n",
      "2025-10-04 20:07:05,544 - INFO - Processing file 265/345: Kota Pangkal Pinang - 2024\n",
      "2025-10-04 20:07:05,617 - INFO - Processing file 266/345: Kota Tanjung Pandan - 2020\n",
      "2025-10-04 20:07:05,693 - INFO - Processing file 267/345: Kota Tanjung Pandan - 2021\n",
      "2025-10-04 20:07:05,768 - INFO - Processing file 268/345: Kota Tanjung Pandan - 2022\n",
      "2025-10-04 20:07:05,903 - INFO - Processing file 269/345: Kota Tanjung Pandan - 2023\n",
      "2025-10-04 20:07:05,979 - INFO - Processing file 270/345: Kota Tanjung Pandan - 2024\n",
      "2025-10-04 20:07:06,055 - INFO - Processing file 271/345: Kota Batam - 2020\n",
      "2025-10-04 20:07:06,135 - INFO - Processing file 272/345: Kota Batam - 2021\n",
      "2025-10-04 20:07:06,212 - INFO - Processing file 273/345: Kota Batam - 2022\n",
      "2025-10-04 20:07:06,282 - INFO - Processing file 274/345: Kota Batam - 2023\n",
      "2025-10-04 20:07:06,354 - INFO - Processing file 275/345: Kota Batam - 2024\n",
      "2025-10-04 20:07:06,488 - INFO - Processing file 276/345: Kota Tanjung Pinang - 2020\n",
      "2025-10-04 20:07:06,559 - INFO - Processing file 277/345: Kota Tanjung Pinang - 2021\n",
      "2025-10-04 20:07:06,632 - INFO - Processing file 278/345: Kota Tanjung Pinang - 2022\n",
      "2025-10-04 20:07:06,707 - INFO - Processing file 279/345: Kota Tanjung Pinang - 2023\n",
      "2025-10-04 20:07:06,781 - INFO - Processing file 280/345: Kota Tanjung Pinang - 2024\n",
      "2025-10-04 20:07:06,852 - INFO - Processing file 281/345: Kota Bandar Lampung - 2020\n",
      "2025-10-04 20:07:06,927 - INFO - Processing file 282/345: Kota Bandar Lampung - 2021\n",
      "2025-10-04 20:07:07,002 - INFO - Processing file 283/345: Kota Bandar Lampung - 2022\n",
      "2025-10-04 20:07:07,077 - INFO - Processing file 284/345: Kota Bandar Lampung - 2023\n",
      "2025-10-04 20:07:07,151 - INFO - Processing file 285/345: Kota Bandar Lampung - 2024\n",
      "2025-10-04 20:07:07,286 - INFO - Processing file 286/345: Kota Metro - 2020\n",
      "2025-10-04 20:07:07,365 - INFO - Processing file 287/345: Kota Metro - 2021\n",
      "2025-10-04 20:07:07,444 - INFO - Processing file 288/345: Kota Metro - 2022\n",
      "2025-10-04 20:07:07,522 - INFO - Processing file 289/345: Kota Metro - 2023\n",
      "2025-10-04 20:07:07,599 - INFO - Processing file 290/345: Kota Metro - 2024\n",
      "2025-10-04 20:07:07,678 - INFO - Processing file 291/345: Kota Dumai - 2020\n",
      "2025-10-04 20:07:07,750 - INFO - Processing file 292/345: Kota Dumai - 2021\n",
      "2025-10-04 20:07:07,883 - INFO - Processing file 293/345: Kota Dumai - 2022\n",
      "2025-10-04 20:07:07,954 - INFO - Processing file 294/345: Kota Dumai - 2023\n",
      "2025-10-04 20:07:08,025 - INFO - Processing file 295/345: Kota Dumai - 2024\n",
      "2025-10-04 20:07:08,098 - INFO - Processing file 296/345: Kota Pekanbaru - 2020\n",
      "2025-10-04 20:07:08,175 - INFO - Processing file 297/345: Kota Pekanbaru - 2021\n",
      "2025-10-04 20:07:08,252 - INFO - Processing file 298/345: Kota Pekanbaru - 2022\n",
      "2025-10-04 20:07:08,332 - INFO - Processing file 299/345: Kota Pekanbaru - 2023\n",
      "2025-10-04 20:07:08,408 - INFO - Processing file 300/345: Kota Pekanbaru - 2024\n",
      "2025-10-04 20:07:08,485 - INFO - Processing file 301/345: Kota Tembilahan - 2020\n",
      "2025-10-04 20:07:08,620 - INFO - Processing file 302/345: Kota Tembilahan - 2021\n",
      "2025-10-04 20:07:08,700 - INFO - Processing file 303/345: Kota Tembilahan - 2022\n",
      "2025-10-04 20:07:08,780 - INFO - Processing file 304/345: Kota Tembilahan - 2023\n",
      "2025-10-04 20:07:08,858 - INFO - Processing file 305/345: Kota Tembilahan - 2024\n",
      "2025-10-04 20:07:08,936 - INFO - Processing file 306/345: Kota Bukittinggi - 2020\n",
      "2025-10-04 20:07:09,008 - INFO - Processing file 307/345: Kota Bukittinggi - 2021\n",
      "2025-10-04 20:07:09,079 - INFO - Processing file 308/345: Kota Bukittinggi - 2022\n",
      "2025-10-04 20:07:09,150 - INFO - Processing file 309/345: Kota Bukittinggi - 2023\n",
      "2025-10-04 20:07:09,282 - INFO - Processing file 310/345: Kota Bukittinggi - 2024\n",
      "2025-10-04 20:07:09,354 - INFO - Processing file 311/345: Kota Padang - 2020\n",
      "2025-10-04 20:07:09,428 - INFO - Processing file 312/345: Kota Padang - 2021\n",
      "2025-10-04 20:07:09,502 - INFO - Processing file 313/345: Kota Padang - 2022\n",
      "2025-10-04 20:07:09,580 - INFO - Processing file 314/345: Kota Padang - 2023\n",
      "2025-10-04 20:07:09,653 - INFO - Processing file 315/345: Kota Padang - 2024\n",
      "2025-10-04 20:07:09,725 - INFO - Processing file 316/345: Kota Lubuk Linggau - 2020\n",
      "2025-10-04 20:07:09,798 - INFO - Processing file 317/345: Kota Lubuk Linggau - 2021\n",
      "2025-10-04 20:07:09,873 - INFO - Processing file 318/345: Kota Lubuk Linggau - 2022\n",
      "2025-10-04 20:07:10,004 - INFO - Processing file 319/345: Kota Lubuk Linggau - 2023\n",
      "2025-10-04 20:07:10,077 - INFO - Processing file 320/345: Kota Lubuk Linggau - 2024\n",
      "2025-10-04 20:07:10,150 - INFO - Processing file 321/345: Kota Palembang - 2020\n",
      "2025-10-04 20:07:10,227 - INFO - Processing file 322/345: Kota Palembang - 2021\n",
      "2025-10-04 20:07:10,303 - INFO - Processing file 323/345: Kota Palembang - 2022\n",
      "2025-10-04 20:07:10,381 - INFO - Processing file 324/345: Kota Palembang - 2023\n",
      "2025-10-04 20:07:10,459 - INFO - Processing file 325/345: Kota Palembang - 2024\n",
      "2025-10-04 20:07:10,535 - INFO - Processing file 326/345: Kota Medan - 2020\n",
      "2025-10-04 20:07:10,677 - INFO - Processing file 327/345: Kota Medan - 2021\n",
      "2025-10-04 20:07:10,750 - INFO - Processing file 328/345: Kota Medan - 2022\n",
      "2025-10-04 20:07:10,825 - INFO - Processing file 329/345: Kota Medan - 2023\n",
      "2025-10-04 20:07:10,899 - INFO - Processing file 330/345: Kota Medan - 2024\n",
      "2025-10-04 20:07:10,974 - INFO - Processing file 331/345: Kota Padang Sidempuan - 2020\n",
      "2025-10-04 20:07:11,053 - INFO - Processing file 332/345: Kota Padang Sidempuan - 2021\n",
      "2025-10-04 20:07:11,130 - INFO - Processing file 333/345: Kota Padang Sidempuan - 2022\n",
      "2025-10-04 20:07:11,210 - INFO - Processing file 334/345: Kota Padang Sidempuan - 2023\n",
      "2025-10-04 20:07:11,288 - INFO - Processing file 335/345: Kota Padang Sidempuan - 2024\n",
      "2025-10-04 20:07:11,437 - INFO - Processing file 336/345: Kota Pematang Siantar - 2020\n",
      "2025-10-04 20:07:11,514 - INFO - Processing file 337/345: Kota Pematang Siantar - 2021\n",
      "2025-10-04 20:07:11,588 - INFO - Processing file 338/345: Kota Pematang Siantar - 2022\n",
      "2025-10-04 20:07:11,664 - INFO - Processing file 339/345: Kota Pematang Siantar - 2023\n",
      "2025-10-04 20:07:11,739 - INFO - Processing file 340/345: Kota Pematang Siantar - 2024\n",
      "2025-10-04 20:07:11,814 - INFO - Processing file 341/345: Kota Sibolga - 2020\n",
      "2025-10-04 20:07:11,891 - INFO - Processing file 342/345: Kota Sibolga - 2021\n",
      "2025-10-04 20:07:11,990 - INFO - Processing file 343/345: Kota Sibolga - 2022\n",
      "2025-10-04 20:07:12,068 - INFO - Processing file 344/345: Kota Sibolga - 2023\n",
      "2025-10-04 20:07:12,209 - INFO - Processing file 345/345: Kota Sibolga - 2024\n",
      "2025-10-04 20:07:12,286 - INFO - Concatenating all processed dataframes\n",
      "2025-10-04 20:07:12,476 - INFO - Data consolidation completed successfully\n",
      "2025-10-04 20:07:12,477 - INFO - Final dataset: 900460 rows, 69 cities, 10 commodities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Data Consolidation Successful!\n",
      "==================================================\n",
      "üìä Dataset Shape: (900460, 5)\n",
      "üèôÔ∏è Cities: 69\n",
      "ü•¨ Commodities: 10\n",
      "üìÖ Date Range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "üí∞ Price Range: 1 - 218,750 IDR\n",
      "üíæ Memory Usage: 164.16 MB\n",
      "\n",
      "üìã Column Information:\n",
      "Commodity            object\n",
      "City                 object\n",
      "Year                 object\n",
      "Date         datetime64[ns]\n",
      "Price                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Execute the consolidation pipeline\n",
    "\"\"\"\n",
    "\n",
    "# Run the consolidation process\n",
    "try:\n",
    "    consolidated_df = consolidate_food_price_data(config)\n",
    "    \n",
    "    # Display basic information about the consolidated dataset\n",
    "    print(\"üéâ Data Consolidation Successful!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìä Dataset Shape: {consolidated_df.shape}\")\n",
    "    print(f\"üèôÔ∏è Cities: {consolidated_df['City'].nunique()}\")\n",
    "    print(f\"ü•¨ Commodities: {consolidated_df['Commodity'].nunique()}\")\n",
    "    print(f\"üìÖ Date Range: {consolidated_df['Date'].min()} to {consolidated_df['Date'].max()}\")\n",
    "    print(f\"üí∞ Price Range: {consolidated_df['Price'].min():,.0f} - {consolidated_df['Price'].max():,.0f} IDR\")\n",
    "    \n",
    "    # Memory usage\n",
    "    memory_usage_mb = consolidated_df.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"üíæ Memory Usage: {memory_usage_mb:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nüìã Column Information:\")\n",
    "    print(consolidated_df.dtypes)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Consolidation failed: {str(e)}\")\n",
    "    print(f\"‚ùå Error: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74794f00",
   "metadata": {},
   "source": [
    "## Data Quality Analysis\n",
    "\n",
    "Let's examine the consolidated data quality and perform some basic exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e81a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Data Quality Report\n",
      "========================================\n",
      "üìä Total Records: 900,460\n",
      "üèôÔ∏è Unique Cities: 69\n",
      "ü•¨ Unique Commodities: 10\n",
      "üìÖ Date Range: 2020-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "üí∞ Price Statistics:\n",
      "   Min Price: 1 IDR\n",
      "   Max Price: 218,750 IDR\n",
      "   Mean Price: 39,354 IDR\n",
      "\n",
      "‚ùì Missing Values:\n",
      "   Price NULLs: 0\n",
      "   Date NULLs: 10\n",
      "\n",
      "‚ö†Ô∏è Quality Issues:\n",
      "   - Found 10 null dates\n",
      "\n",
      "üìã Sample Data (first 10 rows):\n",
      "   Commodity            City Year       Date  Price\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-01-01  41250\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-04-01  41250\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-05-01  41250\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-06-01  41250\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-07-01  33750\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-09-01  31250\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-10-01  32000\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-12-01  39500\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-01-02  43000\n",
      "Bawang Merah Kota Banda Aceh 2020 2020-03-02  37500\n",
      "\n",
      "üèôÔ∏è Cities in Dataset:\n",
      "    1. Kab. Banyumas\n",
      "    2. Kab. Banyuwangi\n",
      "    3. Kab. Boyolali\n",
      "    4. Kab. Bulungan\n",
      "    5. Kab. Bungo\n",
      "    6. Kab. Cilacap\n",
      "    7. Kab. Cirebon\n",
      "    8. Kab. Jember\n",
      "    9. Kab. Karanganyar\n",
      "   10. Kab. Klaten\n",
      "   11. Kab. Kudus\n",
      "   12. Kab. Sragen\n",
      "   13. Kab. Sukoharjo\n",
      "   14. Kab. Sumenep\n",
      "   15. Kab. Tasikmalaya\n",
      "   16. Kab. Wonogiri\n",
      "   17. Kota Balikpapan\n",
      "   18. Kota Banda Aceh\n",
      "   19. Kota Bandar Lampung\n",
      "   20. Kota Bandung\n",
      "   21. Kota Banjarmasin\n",
      "   22. Kota Batam\n",
      "   23. Kota Bekasi\n",
      "   24. Kota Bengkulu\n",
      "   25. Kota Blitar\n",
      "   26. Kota Bogor\n",
      "   27. Kota Bontang\n",
      "   28. Kota Bukittinggi\n",
      "   29. Kota Cilegon\n",
      "   30. Kota Cirebon\n",
      "   31. Kota Depok\n",
      "   32. Kota Dumai\n",
      "   33. Kota Jakarta Pusat\n",
      "   34. Kota Jambi\n",
      "   35. Kota Kediri\n",
      "   36. Kota Lhokseumawe\n",
      "   37. Kota Lubuk Linggau\n",
      "   38. Kota Madiun\n",
      "   39. Kota Malang\n",
      "   40. Kota Medan\n",
      "   41. Kota Metro\n",
      "   42. Kota Meulaboh\n",
      "   43. Kota Padang\n",
      "   44. Kota Padang Sidempuan\n",
      "   45. Kota Palangkaraya\n",
      "   46. Kota Palembang\n",
      "   47. Kota Pangkal Pinang\n",
      "   48. Kota Pekanbaru\n",
      "   49. Kota Pematang Siantar\n",
      "   50. Kota Pontianak\n",
      "   51. Kota Probolinggo\n",
      "   52. Kota Samarinda\n",
      "   53. Kota Sampit\n",
      "   54. Kota Semarang\n",
      "   55. Kota Serang\n",
      "   56. Kota Sibolga\n",
      "   57. Kota Singkawang\n",
      "   58. Kota Sukabumi\n",
      "   59. Kota Surabaya\n",
      "   60. Kota Surakarta (Solo)\n",
      "   61. Kota Tangerang\n",
      "   62. Kota Tanjung\n",
      "   63. Kota Tanjung Pandan\n",
      "   64. Kota Tanjung Pinang\n",
      "   65. Kota Tarakan\n",
      "   66. Kota Tasikmalaya\n",
      "   67. Kota Tegal\n",
      "   68. Kota Tembilahan\n",
      "   69. Kota Yogyakarta\n",
      "\n",
      "ü•¨ Commodities in Dataset:\n",
      "    1. Bawang Merah\n",
      "    2. Bawang Putih\n",
      "    3. Beras\n",
      "    4. Cabai Merah\n",
      "    5. Cabai Rawit\n",
      "    6. Daging Ayam\n",
      "    7. Daging Sapi\n",
      "    8. Gula Pasir\n",
      "    9. Minyak Goreng\n",
      "   10. Telur Ayam\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Quality Analysis and Validation\n",
    "\"\"\"\n",
    "\n",
    "# Perform comprehensive data validation\n",
    "validation_results = validate_processed_data(consolidated_df)\n",
    "\n",
    "print(\"üîç Data Quality Report\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìä Total Records: {validation_results['total_rows']:,}\")\n",
    "print(f\"üèôÔ∏è Unique Cities: {validation_results['total_cities']}\")\n",
    "print(f\"ü•¨ Unique Commodities: {validation_results['total_commodities']}\")\n",
    "print(f\"üìÖ Date Range: {validation_results['date_range']['min_date']} to {validation_results['date_range']['max_date']}\")\n",
    "\n",
    "print(f\"\\nüí∞ Price Statistics:\")\n",
    "print(f\"   Min Price: {validation_results['price_stats']['min_price']:,.0f} IDR\")\n",
    "print(f\"   Max Price: {validation_results['price_stats']['max_price']:,.0f} IDR\")\n",
    "print(f\"   Mean Price: {validation_results['price_stats']['mean_price']:,.0f} IDR\")\n",
    "\n",
    "print(f\"\\n‚ùì Missing Values:\")\n",
    "print(f\"   Price NULLs: {validation_results['missing_values']['price_nulls']}\")\n",
    "print(f\"   Date NULLs: {validation_results['missing_values']['date_nulls']}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Quality Issues:\")\n",
    "if validation_results['quality_issues']:\n",
    "    for issue in validation_results['quality_issues']:\n",
    "        print(f\"   - {issue}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No quality issues detected!\")\n",
    "\n",
    "# Display sample of the data\n",
    "print(f\"\\nüìã Sample Data (first 10 rows):\")\n",
    "print(consolidated_df.head(10).to_string(index=False))\n",
    "\n",
    "# Show unique cities and commodities\n",
    "print(f\"\\nüèôÔ∏è Cities in Dataset:\")\n",
    "cities = sorted(consolidated_df['City'].unique())\n",
    "for i, city in enumerate(cities, 1):\n",
    "    print(f\"   {i:2d}. {city}\")\n",
    "\n",
    "print(f\"\\nü•¨ Commodities in Dataset:\")\n",
    "commodities = sorted(consolidated_df['Commodity'].unique())\n",
    "for i, commodity in enumerate(commodities, 1):\n",
    "    print(f\"   {i:2d}. {commodity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a9004",
   "metadata": {},
   "source": [
    "## Export Consolidated Data\n",
    "\n",
    "Save the consolidated dataset for use in feature engineering and clustering analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "324d0676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Data Export Successful!\n",
      "========================================\n",
      "üìÑ CSV: data\\processed\\food_prices_consolidated_20251004_200720.csv\n",
      "   Size: 42.31 MB\n",
      "üìÑ EXCEL: data\\processed\\food_prices_consolidated_20251004_200720.xlsx\n",
      "   Size: 20.21 MB\n",
      "üìÑ METADATA: data\\processed\\food_prices_consolidated_20251004_200720_metadata.json\n",
      "   Size: 0.00 MB\n",
      "\n",
      "‚úÖ Consolidated dataset ready for feature engineering!\n",
      "üìÅ Files saved in: data/processed/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Export consolidated data to processed directory\n",
    "\"\"\"\n",
    "\n",
    "def export_consolidated_data(df: pd.DataFrame, config: ConsolidationConfig) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Export consolidated DataFrame to multiple formats.\n",
    "    \n",
    "    Args:\n",
    "        df: Consolidated DataFrame to export\n",
    "        config: Configuration object for metadata\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with export file paths\n",
    "    \"\"\"\n",
    "    processed_dir = Path(\"data/processed\")\n",
    "    processed_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate filename with timestamp and configuration info\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    base_filename = f\"food_prices_consolidated_{timestamp}\"\n",
    "    \n",
    "    export_paths = {}\n",
    "    \n",
    "    # Export to CSV (most common format)\n",
    "    csv_path = processed_dir / f\"{base_filename}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    export_paths['csv'] = str(csv_path)\n",
    "    \n",
    "    # Export to Excel (for easy viewing and sharing)\n",
    "    excel_path = processed_dir / f\"{base_filename}.xlsx\"\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    export_paths['excel'] = str(excel_path)\n",
    "    \n",
    "    # Export metadata\n",
    "    metadata = {\n",
    "        'export_timestamp': datetime.now().isoformat(),\n",
    "        'configuration': config.model_dump(),\n",
    "        'data_summary': {\n",
    "            'total_rows': len(df),\n",
    "            'total_cities': df['City'].nunique(),\n",
    "            'total_commodities': df['Commodity'].nunique(),\n",
    "            'date_range': {\n",
    "                'min_date': df['Date'].min().isoformat(),\n",
    "                'max_date': df['Date'].max().isoformat()\n",
    "            },\n",
    "            'cities': sorted(df['City'].unique().tolist()),\n",
    "            'commodities': sorted(df['Commodity'].unique().tolist())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    metadata_path = processed_dir / f\"{base_filename}_metadata.json\"\n",
    "    import json\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "    export_paths['metadata'] = str(metadata_path)\n",
    "    \n",
    "    return export_paths\n",
    "\n",
    "# Export the consolidated data\n",
    "try:\n",
    "    export_paths = export_consolidated_data(consolidated_df, config)\n",
    "    \n",
    "    print(\"üíæ Data Export Successful!\")\n",
    "    print(\"=\" * 40)\n",
    "    for format_type, file_path in export_paths.items():\n",
    "        file_size = Path(file_path).stat().st_size / 1024**2  # MB\n",
    "        print(f\"üìÑ {format_type.upper()}: {file_path}\")\n",
    "        print(f\"   Size: {file_size:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Consolidated dataset ready for feature engineering!\")\n",
    "    print(f\"üìÅ Files saved in: data/processed/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Export failed: {str(e)}\")\n",
    "    print(f\"‚ùå Export Error: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141514a1",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "1. ‚úÖ **Modular Design**: Broke down the consolidation process into well-defined, reusable functions\n",
    "2. ‚úÖ **Configuration Management**: Used Pydantic for type-safe configuration with validation\n",
    "3. ‚úÖ **Error Handling**: Comprehensive error handling and logging throughout the pipeline\n",
    "4. ‚úÖ **Data Quality**: Built-in validation and quality checks\n",
    "5. ‚úÖ **Documentation**: Clear docstrings and type hints for all functions\n",
    "6. ‚úÖ **Export**: Multiple output formats (CSV, Parquet) with metadata\n",
    "\n",
    "### Key Improvements Made:\n",
    "- **Type Safety**: All functions have proper type hints\n",
    "- **Error Resilience**: Graceful handling of file processing errors\n",
    "- **Logging**: Structured logging for debugging and monitoring  \n",
    "- **Memory Efficiency**: Categorical data types for string columns\n",
    "- **Validation**: Comprehensive data quality checks\n",
    "- **Modularity**: Each function has a single responsibility\n",
    "- **Configuration**: Centralized, validated configuration management\n",
    "\n",
    "### Next Steps:\n",
    "1. **Feature Engineering** (`02_feature_engineering.ipynb`):\n",
    "   - Extract 3 features per commodity (average, CV, trend)\n",
    "   - Create the 30-feature matrix for clustering\n",
    "   \n",
    "2. **Clustering Experiments** (`03_clustering_experiments.ipynb`):\n",
    "   - Implement K-Means, Fuzzy C-Means, and Spectral Clustering\n",
    "   - Find optimal number of clusters\n",
    "   - Compare algorithm performance\n",
    "\n",
    "3. **Pipeline Validation** (`04_pipeline_validation.ipynb`):\n",
    "   - End-to-end testing\n",
    "   - Performance benchmarking\n",
    "   - Prepare for modularization\n",
    "\n",
    "The consolidated dataset is now ready for the feature engineering phase! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
